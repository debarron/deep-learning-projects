{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages (5.1.0)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n",
    "!KERAS_BACKEND=tensorflow python -c \"from keras import backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input metadata\n",
    "img_width, img_height = 150, 150\n",
    "ds_train = \"./data/train\"\n",
    "ds_test = \"./data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Divide the data\n",
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "gen_train = data_gen.flow_from_directory(\n",
    "    ds_train, \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=16, \n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "gen_test = data_gen.flow_from_directory(\n",
    "    ds_test, \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=32, \n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "def network_generators(train_dir, test_dir, img_w, img_h, train_batch, test_batch):\n",
    "    data_generator = ImageDataGenerator(rescale=1./255)\n",
    "    gen_train = data_generator.flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(img_w, img_h), \n",
    "        batch_size=train_batch, \n",
    "        class_mode=\"binary\"\n",
    "    )\n",
    "    gen_test = data_gen.flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(img_w, img_h), \n",
    "        batch_size=test_batch, \n",
    "        class_mode=\"binary\"\n",
    "    )\n",
    "    \n",
    "    return (gen_train, gen_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#### MODELS\n",
    "#######################################\n",
    "\n",
    "# Copy-paste model\n",
    "def model_naive(img_w, img_h):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Larger model, with relu at the end\n",
    "def model_larger(img_w, img_h):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "# model = model_naive(img_width, img_height) [0.4223675976256625, 0.8190354567307693]\n",
    "# model = model_larger(img_width, img_height) [7.990353628993034, 0.0]\n",
    "model = model_naive(img_width, img_height)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 30\n",
    "nb_train_samples = 2048\n",
    "nb_validation_samples = 832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=30, steps_per_epoch=128, validation_steps=832, validation_data=<keras_pre...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "128/128 [==============================] - 14s 107ms/step - loss: 7.9929 - acc: 0.0098 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "128/128 [==============================] - 13s 101ms/step - loss: 7.8469 - acc: 0.0283 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 3/30\n",
      "128/128 [==============================] - 13s 100ms/step - loss: 7.9573 - acc: 9.7656e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 7.7789 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.9089 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 8.1658 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 7/30\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 8.0724 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 8/30\n",
      "128/128 [==============================] - 13s 104ms/step - loss: 8.0724 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 9/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.9790 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 10/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.8856 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 11/30\n",
      "128/128 [==============================] - 13s 101ms/step - loss: 7.9011 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 12/30\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 7.8389 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 13/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.6521 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 14/30\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 7.9168 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 15/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.8856 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 16/30\n",
      "128/128 [==============================] - 13s 104ms/step - loss: 7.8934 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 17/30\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 8.2593 - acc: 9.7656e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 18/30\n",
      "128/128 [==============================] - 13s 104ms/step - loss: 7.9556 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 19/30\n",
      "128/128 [==============================] - 13s 101ms/step - loss: 8.3994 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 20/30\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 7.9012 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 21/30\n",
      "128/128 [==============================] - 13s 104ms/step - loss: 8.0882 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 22/30\n",
      "128/128 [==============================] - 13s 101ms/step - loss: 7.9401 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 23/30\n",
      "128/128 [==============================] - 13s 101ms/step - loss: 7.9402 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 24/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.9245 - acc: 9.7656e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 25/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 8.0023 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 26/30\n",
      "128/128 [==============================] - 13s 100ms/step - loss: 8.1815 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 27/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.9712 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 28/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.7610 - acc: 4.8828e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 29/30\n",
      "128/128 [==============================] - 13s 103ms/step - loss: 8.1580 - acc: 0.0000e+00 - val_loss: 7.9712 - val_acc: 0.0000e+00\n",
      "Epoch 30/30\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 7.6755 - acc: 9.7656e-04 - val_loss: 7.9712 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaab7eb550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        gen_train,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=gen_test,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models/cnn_20_epochs.h5\")\n",
    "#model.save_weights(\"models/cnn_larger_20_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.990353628993034, 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(gen_train, nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
      "  \n",
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  if sys.path[0] == '':\n",
      "/home/daniel/anaconda3/envs/rocmtf/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = model_naive(img_width, img_height)\n",
    "model.load_weights(\"models/cnn_larger_20_epochs.h5\")\n",
    "\n",
    "\n",
    "img_path = './data/predict/dog_3.jpg'\n",
    "img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for x in range(1, 3):\n",
    "    print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
